---
title: "Coursera Data Science Speclization: Getting and Cleaning Data, Week 4 Project"
date: "May 1, 2016"
output: html_document
---

# About This Document

This is a code book that describes the variables, the data, and any transformations or work that I performed to clean up the data for the Coursera Data Science Specialization, Week 4 assignment. This data involves the UCI HAR Accelerometer data.

## Data Source Links:
* Original Data Source: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
* Data Source Website: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones

## Data Items Utilized in Analysis:

The following items in the raw dataset were utilized for this analysis, all located in the UCI HAR Dataset directory:

### Feature information
* features.txt
      + Contains ID information and label descriptions for each tested feature.

### Testing and Training information
* subject\_test.txt, subject\_train.txt
      + Contains details about subjects in the test set.

* X\_test.txt, X\_train.txt
      + Contains details regarding the observations of each feature.

* Y\_test.txt, Y\_train.txt
      + Contains key values allowing feature names to be related to their descriptions (foreign key to activity_labels.txt)

## Transformation Goals

1. Merges the training and the test sets to create one data set.
2. Extracts only the measurements on the mean and standard deviation for each measurement.
3. Uses descriptive activity names to name the activities in the data set
4. Appropriately labels the data set with descriptive activity names.
5. Creates a second, independent tidy data set with the average of each variable for each activity and each subject.

## Script Utilization

The ```run_analysis.R``` script performs the following steps to reach its goal:

1. Downloads and unzips the necessary files.
2. Imports all necessary datasets.
3. Merges all datasets.
4. Renames necessary fields via:
      + Direct renaming of the fields (subject and activity fields).
      + Merging/joining to foreign keys (features.txt file to Y_* datasets).
      + Using GREP and GSUB to match patterns for further clarification or subsetting.
5. Writes a tidy table by utilizing the ```plyr``` package and applying a column wise mean to each feature by subject and activity type.
